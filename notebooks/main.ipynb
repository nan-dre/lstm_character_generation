{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import json\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Loading the training data\n",
    "path = '../data/manele-merged.json'\n",
    "text = []\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    file = json.load(f)\n",
    "    for manea in file:\n",
    "        for lyric in manea['lyrics']:\n",
    "            text.append(lyric)\n",
    "text = ''.join(text)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Cleaning the text\n",
    "text = text.lower()\n",
    "to_replace = list('!\"$&()*+/:;<=>@[]^_~{}#%\\\\|–…\\ufeff\\xa0§«»')\n",
    "to_replace.append(\"'\")\n",
    "to_replace.append(\"refren\")\n",
    "to_replace.append(\"ref\")\n",
    "to_replace.append(\"x2\")\n",
    "to_replace.append(\"2x\")\n",
    "to_replace.append(\"florin salam\")\n",
    "to_replace.append(\"salam\")\n",
    "to_replace.append(\"bis\")\n",
    "\n",
    "for word in to_replace:\n",
    "    text = text.replace(word, '')\n",
    "    pass\n",
    "text = re.sub('â|ă|а', 'a', text)\n",
    "text = re.sub('í|î|ï|і|ἰ', 'i', text)\n",
    "text = re.sub('ş|ș|ѕ', 's', text)\n",
    "text = re.sub('ţ', 't', text)\n",
    "text = re.sub('ν', 'v', text)\n",
    "text = re.sub('в', 'b', text)\n",
    "text = re.sub('е', 'e', text)\n",
    "text = re.sub('к', 'k', text)\n",
    "text = re.sub('м', 'm', text)\n",
    "text = re.sub('н', 'h', text)\n",
    "text = re.sub('о', 'o', text)\n",
    "text = re.sub('р', 'p', text)\n",
    "text = re.sub('с', 'c', text)\n",
    "text = re.sub('т', 't', text)\n",
    "text = re.sub('у', 'y', text)\n",
    "text = re.sub('х', 'x', text)\n",
    "text = re.sub('ј', 'j', text)\n",
    "\n",
    "\n",
    "text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "text = re.sub(r'\\.{4,}', '...', text)\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars)\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Corpus length: 1584499\n",
      "['\\n', ' ', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'B', 'H', 'K', 'M', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Total chars: 47\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 100\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def sample(preds, temperature=1.0):\r\n",
    "    # helper function to sample an index from a probability array\r\n",
    "    preds = np.asarray(preds).astype(\"float64\")\r\n",
    "    preds = np.log(preds) / temperature\r\n",
    "    exp_preds = np.exp(preds)\r\n",
    "    preds = exp_preds / np.sum(exp_preds)\r\n",
    "    probas = np.random.multinomial(1, preds, 1)\r\n",
    "    return np.argmax(probas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "epochs = 15 \r\n",
    "batch_size = 128 \r\n",
    "\r\n",
    "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "1036/1036 [==============================] - 96s 76ms/step - loss: 2.3902\n",
      "Epoch 2/15\n",
      "1036/1036 [==============================] - 79s 76ms/step - loss: 1.9048\n",
      "Epoch 3/15\n",
      "1036/1036 [==============================] - 82s 79ms/step - loss: 1.6867\n",
      "Epoch 4/15\n",
      "1036/1036 [==============================] - 79s 76ms/step - loss: 1.5471\n",
      "Epoch 5/15\n",
      "1036/1036 [==============================] - 79s 76ms/step - loss: 1.4329\n",
      "Epoch 6/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 1.3327\n",
      "Epoch 7/15\n",
      "1036/1036 [==============================] - 77s 75ms/step - loss: 1.2426\n",
      "Epoch 8/15\n",
      "1036/1036 [==============================] - 79s 76ms/step - loss: 1.1619\n",
      "Epoch 9/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 1.0868\n",
      "Epoch 10/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 1.0200\n",
      "Epoch 11/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 0.9596\n",
      "Epoch 12/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 0.9059\n",
      "Epoch 13/15\n",
      "1036/1036 [==============================] - 78s 75ms/step - loss: 0.8532\n",
      "Epoch 14/15\n",
      "1036/1036 [==============================] - 83s 80ms/step - loss: 0.8106\n",
      "Epoch 15/15\n",
      "1036/1036 [==============================] - 83s 80ms/step - loss: 0.7753\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b730388320>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "generated_length = 300\r\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\r\n",
    "for diversity in [0.2, 0.5]:\r\n",
    "    print(\"...Diversity:\", diversity)\r\n",
    "\r\n",
    "    generated = \"\"\r\n",
    "    original_sentence = text[start_index : start_index + maxlen]\r\n",
    "    sentence = original_sentence\r\n",
    "    print('...Generating with seed:\\n \"' + sentence + '\"')\r\n",
    "\r\n",
    "    for i in range(generated_length):\r\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\r\n",
    "        for t, char in enumerate(sentence):\r\n",
    "            x_pred[0, t, char_indices[char]] = 1.0\r\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\r\n",
    "        next_index = sample(preds, diversity)\r\n",
    "        next_char = indices_char[next_index]\r\n",
    "        sentence = sentence[1:] + next_char\r\n",
    "        generated += next_char\r\n",
    "\r\n",
    "    print(\"...Generated:\\n\", original_sentence + generated)\r\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...Diversity: 0.2\n",
      "...Generating with seed:\n",
      " \"u urata ii viata mea\n",
      "buna sau rea eu tot vreau sa las ceva in urma mea\n",
      "ca viata mea e si buna si rea\"\n",
      "...Generated:\n",
      " u urata ii viata mea\n",
      "buna sau rea eu tot vreau sa las ceva in urma mea\n",
      "ca viata mea e si buna si rea\n",
      "sa mor de la mine nu te las la mine\n",
      "si te iubesc da nu ma vrei sa iti dovedesc\n",
      "\n",
      "ca tine nu te voi iubii\n",
      "\n",
      "te-ai jucat cu mine\n",
      "dar nu te vad nici atat de dor\n",
      "\n",
      "mi-e dor, mi-e dor de ea\n",
      "intr-o zi sa ma iubesti\n",
      "nu mi-am promis lu teata viata mea\n",
      "ca eu nu te intoarce\n",
      "si nu te vad nici o sa mai fi sa fiu \n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed:\n",
      " \"u urata ii viata mea\n",
      "buna sau rea eu tot vreau sa las ceva in urma mea\n",
      "ca viata mea e si buna si rea\"\n",
      "...Generated:\n",
      " u urata ii viata mea\n",
      "buna sau rea eu tot vreau sa las ceva in urma mea\n",
      "ca viata mea e si buna si rea\n",
      "pe dragostea mea\n",
      "sa pot sa uit ca voi traiesc\n",
      "si sa te rau inima chiara\n",
      "\n",
      "mi-e dor, mi-e dor de ea\n",
      "dormi adintrimile si foricine\n",
      "\n",
      "azi ma iubeste dumnezeu\n",
      "ma doare mi-a pasasit\n",
      "am tot sa mi-am dat seama cu adevarat\n",
      "eu mara de la viata mea\n",
      "sa sa te iubeasca te iubesc\n",
      "\n",
      "pentru perte ta si cu tine \n",
      "\n",
      "vin \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model.save(\"model-15-0.7753.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Save weights in hdf5 format\r\n",
    "filepath=\"model-{epoch:02d}-{loss:.4f}.h5\"\r\n",
    "checkpoint = ModelCheckpoint(filepath + \".hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('deeplearning': conda)"
  },
  "interpreter": {
   "hash": "eddcb13c0afbe40eff33f8afdc713c878396e4478ab766ce2943b14c50b9ae00"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}